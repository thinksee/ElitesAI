{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归\n",
    "    - 线性回归的基本要素\n",
    "    - 线性回归模型从零开始的实现\n",
    "    - 线性回归模型使用pytorch的简洁实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归的基本要素\n",
    "\n",
    "### 模型\n",
    "为了简单起见，这里我们假设价格只取决于房屋状况的两个因素，即面积（平方米）和房龄（年）。接下来我们希望探索价格与这两个因素的具体关系。线性回归假设输出与各个输入之间是线性关系:\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathrm{price} = w_{\\mathrm{area}} \\cdot \\mathrm{area} + w_{\\mathrm{age}} \\cdot \\mathrm{age} + b\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### 数据集\n",
    "我们通常收集一系列的真实数据，例如多栋房屋的真实售出价格和它们对应的面积和房龄。我们希望在这个数据上面寻找模型参数来使模型的预测价格与真实价格的误差最小。在机器学习术语里，该数据集被称为训练数据集（training data set）或训练集（training set），一栋房屋被称为一个样本（sample），其真实售出价格叫作标签（label），用来预测标签的两个因素叫作特征（feature）。特征用来表征样本的特点。\n",
    "### 损失函数\n",
    "在模型训练中，我们需要衡量价格预测值与真实值之间的误差。通常我们会选取一个非负数作为误差，且数值越小表示误差越小。一个常用的选择是平方函数。 它在评估索引为 $i$ 的样本误差的表达式为\n",
    "\n",
    "\n",
    "$$\n",
    "l^{(i)}(\\mathbf{w}, b) = \\frac{1}{2} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2,\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "L(\\mathbf{w}, b) =\\frac{1}{n}\\sum_{i=1}^n l^{(i)}(\\mathbf{w}, b) =\\frac{1}{n} \\sum_{i=1}^n \\frac{1}{2}\\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right)^2.\n",
    "$$\n",
    "\n",
    "\n",
    "### 优化函数 - 随机梯度下降\n",
    "当模型和损失函数形式较为简单时，上面的误差最小化问题的解可以直接用公式表达出来。这类解叫作解析解（analytical solution）。本节使用的线性回归和平方误差刚好属于这个范畴。然而，大多数深度学习模型并没有解析解，只能通过优化算法有限次迭代模型参数来尽可能降低损失函数的值。这类解叫作数值解（numerical solution）。\n",
    "\n",
    "在求数值解的优化算法中，小批量随机梯度下降（mini-batch stochastic gradient descent）在深度学习中被广泛使用。它的算法很简单：先选取一组模型参数的初始值，如随机选取；接下来对参数进行多次迭代，使每次迭代都可能降低损失函数的值。在每次迭代中，先随机均匀采样一个由固定数目训练数据样本所组成的小批量（mini-batch）$\\mathcal{B}$，然后求小批量中数据样本的平均损失有关模型参数的导数（梯度），最后用此结果与预先设定的一个正数的乘积作为模型参数在本次迭代的减小量。   \n",
    "\n",
    "$$\n",
    "(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_{(\\mathbf{w},b)} l^{(i)}(\\mathbf{w},b)\n",
    "$$\n",
    "  \n",
    "学习率: $\\eta$代表在每次优化中，能够学习的步长的大小    \n",
    "批量大小: $\\mathcal{B}$是小批量计算中的批量大小batch size   \n",
    "\n",
    "总结一下，优化函数的有以下两个步骤：\n",
    "\n",
    "- (i)初始化模型参数，一般来说使用随机初始化；\n",
    "- (ii)我们在数据上迭代多次，通过在负梯度方向移动参数来更新每个参数。\n",
    "\n",
    "**注意**\n",
    "梯度上升还是梯度下降和目标优化函数是一直的，若想要优化函数越小，则采用梯度下降，若想要优化函数越大，则采用梯度上升"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "n = 1000\n",
    "a = torch.ones(n)\n",
    "b = torch.ones(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a timer class to record time\n",
    "class Timer(object):\n",
    "    \"\"\"Record multiple running times.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        # start the timer\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        # stop the timer and record time into a list\n",
    "        self.times.append(time.time() - self.start_time)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        # calculate the average and return\n",
    "        return sum(self.times)/len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        # return the sum of recorded time\n",
    "        return sum(self.times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.08794 sec'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = Timer()\n",
    "c = torch.zeros(n)\n",
    "for i in range(n):\n",
    "    c[i] = a[i] + b[i]\n",
    "'%.5f sec' % timer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00300 sec'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer.start()\n",
    "d = a + b\n",
    "'%.5f sec' % timer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### 线性回归模型从0开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成数据集\n",
    "使用线性模型随机生成数据集，生成1000个样本数据集，下面是用来生成数据的线性关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_inputs = 2\n",
    "nb_examples = 1000\n",
    "# set true weight and bias in order to generate corresponded label\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "\n",
    "features = torch.randn(nb_examples, nb_inputs,\n",
    "                      dtype=torch.float32)\n",
    "labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\n",
    "labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()),\n",
    "                       dtype=torch.float32)  # 添加噪音"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(features[:, 1].numpy(), labels.numpy(), 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据读写器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))  # \n",
    "    random.shuffle(indices)  # random read 10 samples\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)]) # the last time may be not enough for a whole batch\n",
    "        yield  features.index_select(0, j), labels.index_select(0, j)  # 进行行维度的选择，即每次选择j行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2110,  0.0674],\n",
      "        [-0.8305,  0.6743],\n",
      "        [-0.3478,  0.9420],\n",
      "        [ 1.9382, -0.4983],\n",
      "        [-1.0234, -0.6619],\n",
      "        [-0.8195, -3.0215],\n",
      "        [ 0.0692,  0.5660],\n",
      "        [ 0.7709, -1.1119],\n",
      "        [ 0.3937,  0.7820],\n",
      "        [-0.1800,  0.2354]]) \n",
      " tensor([ 4.3886,  0.2436,  0.2964,  9.7705,  4.4152, 12.8332,  2.4064,  9.5423,\n",
      "         2.3240,  3.0581])\n"
     ]
    }
   ],
   "source": [
    "# test data_iter\n",
    "batch_size = 10\n",
    "\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0068],\n",
      "        [0.0024]]) tensor([0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor(np.random.normal(0, 0.01, (nb_inputs, 1)), dtype=torch.float32)\n",
    "b = torch.zeros(1, dtype=torch.float32)\n",
    "print(w,b)\n",
    "w.requires_grad_(requires_grad=True)  # 是否参与梯度下降\n",
    "b.requires_grad_(requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义模型\n",
    "使用简单的线性归回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X, w, b):\n",
    "    return torch.mm(X, w) + b  # 矩阵乘法+广播机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义损失函数\n",
    "**问题2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y):   # 均方误差\n",
    "#     return (y_hat - y.view(y_hat.size())) ** 2 / 2\n",
    "    return (y_hat.view(-1) - y) ** 2 / 2\n",
    "#     return -(y_hat - y.view(-1)) ** 2 / 2  # \n",
    "#     return (y_hat - y.view(y_hat.shape)) ** 2 / 2\n",
    "#     return (y_hat - y.view(-1, 1)) ** 2 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里采用优化函数使用的是小批量随机梯度下降\n",
    "def sgd(params, lr, batch_size): \n",
    "    for param in params:\n",
    "        param.data += lr * param.grad / batch_size # ues .data to operate param without gradient track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.37577 sec'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# super parameters init\n",
    "lr = 0.03 # learning rate\n",
    "num_epochs = 5\n",
    "\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "timer = Timer()\n",
    "# training\n",
    "for epoch in range(num_epochs):  # training repeats num_epochs times\n",
    "    # in each epoch, all the samples in dataset will be used once\n",
    "    \n",
    "    # X is the feature and y is the label of a batch sample\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        l = loss(net(X, w, b), y).sum() \n",
    "        \n",
    "        # calculate the gradient of batch sample loss \n",
    "        l.backward()  \n",
    "        # using small batch random gradient descent to iter model parameters\n",
    "        sgd([w, b], lr, batch_size)  \n",
    "        # reset parameter gradient\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "    train_l = loss(net(features, w, b), labels)\n",
    "'%.5f sec' % timer.stop()  \n",
    "#     print(net(features, w, b).shape, labels.shape) # 所以labels需要扩展\n",
    "#     print('epoch %d, loss %f' % (epoch + 1, train_l.mean().item()))\n",
    "# print(net(features, w, b).shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1121)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squared_loss(torch.Tensor([2.33, 1.07, 1.23]), torch.Tensor([3.14, 0.98, 1.32])).sum()/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### 线性模型pytorch简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "torch.manual_seed(2020)\n",
    "\n",
    "torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成数据集\n",
    "和之前一样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用utils.data读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "# combine featues and labels of dataset\n",
    "dataset = Data.TensorDataset(features, labels)\n",
    "data_iter = Data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,  # 使用多线程读取\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6414,  0.0122],\n",
      "        [ 0.4468, -2.6335],\n",
      "        [-0.3769,  0.4390],\n",
      "        [-1.1532,  0.2595],\n",
      "        [-1.7146, -0.1833],\n",
      "        [ 0.1806, -0.4321],\n",
      "        [ 0.8752,  1.1701],\n",
      "        [-0.8961, -1.3425],\n",
      "        [ 0.5695, -1.0889],\n",
      "        [ 0.4538, -0.5142]]) \n",
      " tensor([ 5.4475, 14.0564,  1.9508,  1.0137,  1.4047,  6.0302,  1.9873,  6.9710,\n",
      "         9.0265,  6.8472])\n"
     ]
    }
   ],
   "source": [
    "## 测试\n",
    "for X, y in data_iter:\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearNet(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, n_feature):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.linear = nn.Linear(n_feature, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        return y\n",
    "net = LinearNet(nb_inputs)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "Linear(in_features=2, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "## 扩展为多层序列模型\n",
    "# 方式1\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(nb_inputs, 1)\n",
    ")\n",
    "# 方式2\n",
    "net = nn.Sequential()\n",
    "net.add_module('linear', nn.Linear(nb_inputs, 1))\n",
    "# 方法3\n",
    "from collections import OrderedDict\n",
    "net = nn.Sequential(OrderedDict([\n",
    "          ('linear', nn.Linear(nb_inputs, 1))\n",
    "          # ......\n",
    "        ]))\n",
    "print(net)\n",
    "print(net[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import init\n",
    "\n",
    "init.normal_(net[0].weight, mean=0.0, std=0.01)\n",
    "init.constant_(net[0].bias, val=0.0)  # or you can use `net[0].bias.data.fill_(0)` to modify it directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0016,  0.0022]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 调用损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.03\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.03)   # built-in random gradient descent function\n",
    "print(optimizer)  # function prototype: `torch.optim.SGD(params, lr=, momentum=0, dampening=0, weight_decay=0, nesterov=False)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'15.34452 sec'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = Timer()\n",
    "num_epochs = 5\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for X, y in data_iter:\n",
    "        output = net(X)\n",
    "        l = loss(output, y.view(-1, 1))\n",
    "        optimizer.zero_grad() # reset gradient, equal to net.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "'%.5f sec' % timer.stop()\n",
    "#     print('epoch %d, loss: %f' % (epoch, l.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, -3.4] tensor([[ 2.0005, -3.3993]])\n",
      "4.2 tensor([4.1998])\n"
     ]
    }
   ],
   "source": [
    "## 结果对比\n",
    "dense = net[0]\n",
    "print(true_w, dense.weight.data)\n",
    "print(true_b, dense.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 两种方式对比\n",
    "- 从0开始可以理解Linear Regression的模型原理，pytorch可以加快模型构建\n",
    "- 时间上，pytorch的编码并没有提升"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归\n",
    "    - 线性回归的基本要素\n",
    "    - 线性回归模型从零开始的实现\n",
    "    - 线性回归模型使用pytorch的简洁实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归的基本要素\n",
    "\n",
    "### 模型\n",
    "为了简单起见，这里我们假设价格只取决于房屋状况的两个因素，即面积（平方米）和房龄（年）。接下来我们希望探索价格与这两个因素的具体关系。线性回归假设输出与各个输入之间是线性关系:\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathrm{price} = w_{\\mathrm{area}} \\cdot \\mathrm{area} + w_{\\mathrm{age}} \\cdot \\mathrm{age} + b\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### 数据集\n",
    "我们通常收集一系列的真实数据，例如多栋房屋的真实售出价格和它们对应的面积和房龄。我们希望在这个数据上面寻找模型参数来使模型的预测价格与真实价格的误差最小。在机器学习术语里，该数据集被称为训练数据集（training data set）或训练集（training set），一栋房屋被称为一个样本（sample），其真实售出价格叫作标签（label），用来预测标签的两个因素叫作特征（feature）。特征用来表征样本的特点。\n",
    "### 损失函数\n",
    "在模型训练中，我们需要衡量价格预测值与真实值之间的误差。通常我们会选取一个非负数作为误差，且数值越小表示误差越小。一个常用的选择是平方函数。 它在评估索引为 $i$ 的样本误差的表达式为\n",
    "\n",
    "\n",
    "$$\n",
    "l^{(i)}(\\mathbf{w}, b) = \\frac{1}{2} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2,\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "L(\\mathbf{w}, b) =\\frac{1}{n}\\sum_{i=1}^n l^{(i)}(\\mathbf{w}, b) =\\frac{1}{n} \\sum_{i=1}^n \\frac{1}{2}\\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right)^2.\n",
    "$$\n",
    "\n",
    "\n",
    "### 优化函数 - 随机梯度下降\n",
    "当模型和损失函数形式较为简单时，上面的误差最小化问题的解可以直接用公式表达出来。这类解叫作解析解（analytical solution）。本节使用的线性回归和平方误差刚好属于这个范畴。然而，大多数深度学习模型并没有解析解，只能通过优化算法有限次迭代模型参数来尽可能降低损失函数的值。这类解叫作数值解（numerical solution）。\n",
    "\n",
    "在求数值解的优化算法中，小批量随机梯度下降（mini-batch stochastic gradient descent）在深度学习中被广泛使用。它的算法很简单：先选取一组模型参数的初始值，如随机选取；接下来对参数进行多次迭代，使每次迭代都可能降低损失函数的值。在每次迭代中，先随机均匀采样一个由固定数目训练数据样本所组成的小批量（mini-batch）$\\mathcal{B}$，然后求小批量中数据样本的平均损失有关模型参数的导数（梯度），最后用此结果与预先设定的一个正数的乘积作为模型参数在本次迭代的减小量。   \n",
    "\n",
    "$$\n",
    "(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_{(\\mathbf{w},b)} l^{(i)}(\\mathbf{w},b)\n",
    "$$\n",
    "  \n",
    "学习率: $\\eta$代表在每次优化中，能够学习的步长的大小    \n",
    "批量大小: $\\mathcal{B}$是小批量计算中的批量大小batch size   \n",
    "\n",
    "总结一下，优化函数的有以下两个步骤：\n",
    "\n",
    "- (i)初始化模型参数，一般来说使用随机初始化；\n",
    "- (ii)我们在数据上迭代多次，通过在负梯度方向移动参数来更新每个参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "n = 1000\n",
    "a = torch.ones(n)\n",
    "b = torch.ones(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a timer class to record time\n",
    "class Timer(object):\n",
    "    \"\"\"Record multiple running times.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        # start the timer\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        # stop the timer and record time into a list\n",
    "        self.times.append(time.time() - self.start_time)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        # calculate the average and return\n",
    "        return sum(self.times)/len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        # return the sum of recorded time\n",
    "        return sum(self.times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.07795 sec'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = Timer()\n",
    "c = torch.zeros(n)\n",
    "for i in range(n):\n",
    "    c[i] = a[i] + b[i]\n",
    "'%.5f sec' % timer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00000 sec'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer.start()\n",
    "d = a + b\n",
    "'%.5f sec' % timer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### 线性回归模型从0开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成数据集\n",
    "使用线性模型随机生成数据集，生成1000个样本数据集，下面是用来生成数据的线性关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_inputs = 2\n",
    "nb_examples = 1000\n",
    "# set true weight and bias in order to generate corresponded label\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "\n",
    "features = torch.randn(nb_examples, nb_inputs,\n",
    "                      dtype=torch.float32)\n",
    "labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\n",
    "labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()),\n",
    "                       dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(features[:, 1].numpy(), labels.numpy(), 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据读写器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))  # \n",
    "    random.shuffle(indices)  # random read 10 samples\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)]) # the last time may be not enough for a whole batch\n",
    "        yield  features.index_select(0, j), labels.index_select(0, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4481, -1.1651],\n",
      "        [-1.0472,  1.5496],\n",
      "        [ 2.1043,  1.1281],\n",
      "        [-1.7444, -0.9544],\n",
      "        [-0.6622, -0.6759],\n",
      "        [ 1.8944,  0.7977],\n",
      "        [-0.9631, -0.1335],\n",
      "        [ 1.3772, -0.6647],\n",
      "        [-2.4199, -0.6276],\n",
      "        [-0.2525,  0.1273]]) \n",
      " tensor([ 9.0461, -3.1711,  4.5615,  3.9676,  5.1820,  5.2632,  2.7330,  9.2195,\n",
      "         1.4683,  3.2611])\n"
     ]
    }
   ],
   "source": [
    "# test data_iter\n",
    "batch_size = 10\n",
    "\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor(np.random.normal(0, 0.01, (nb_inputs, 1)), dtype=torch.float32)\n",
    "b = torch.zeros(1, dtype=torch.float32)\n",
    "\n",
    "w.requires_grad_(requires_grad=True)\n",
    "b.requires_grad_(requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义模型\n",
    "使用简单的线性归回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X, w, b):\n",
    "    return torch.mm(X, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y):   # 均方误差\n",
    "#     return (y_hat - y.view(y_hat.size())) ** 2 / 2\n",
    "#     return (y_hat.view(-1) - y) ** 2 / 2\n",
    "    return (y_hat - y.view(-1)) ** 2 / 2  # \n",
    "#     return (y_hat - y.view(y_hat.shape)) ** 2 / 2\n",
    "#     return (y_hat - y.view(-1, 1)) ** 2 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里采用优化函数使用的是小批量随机梯度下降\n",
    "def sgd(params, lr, batch_size): \n",
    "    for param in params:\n",
    "        param.data -= lr * param.grad / batch_size # ues .data to operate param without gradient track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1]) torch.Size([1000])\n",
      "epoch 1, loss 8.161527\n",
      "torch.Size([1000, 1]) torch.Size([1000])\n",
      "epoch 2, loss 8.347056\n",
      "torch.Size([1000, 1]) torch.Size([1000])\n",
      "epoch 3, loss 8.196112\n",
      "torch.Size([1000, 1]) torch.Size([1000])\n",
      "epoch 4, loss 8.211898\n",
      "torch.Size([1000, 1]) torch.Size([1000])\n",
      "epoch 5, loss 8.091971\n"
     ]
    }
   ],
   "source": [
    "# super parameters init\n",
    "lr = 0.03 # learning rate\n",
    "num_epochs = 5\n",
    "\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "# training\n",
    "for epoch in range(num_epochs):  # training repeats num_epochs times\n",
    "    # in each epoch, all the samples in dataset will be used once\n",
    "    \n",
    "    # X is the feature and y is the label of a batch sample\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        l = loss(net(X, w, b), y).sum() \n",
    "        \n",
    "        # calculate the gradient of batch sample loss \n",
    "        l.backward()  \n",
    "        # using small batch random gradient descent to iter model parameters\n",
    "        sgd([w, b], lr, batch_size)  \n",
    "        # reset parameter gradient\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "    train_l = loss(net(features, w, b), labels)\n",
    "    print(net(features, w, b).shape, labels.shape) # 所以labels需要扩展\n",
    "    print('epoch %d, loss %f' % (epoch + 1, train_l.mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1121)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squared_loss(torch.Tensor([2.33, 1.07, 1.23]), torch.Tensor([3.14, 0.98, 1.32])).sum()/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### 线性模型pytorch简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "torch.manual_seed(2020)\n",
    "\n",
    "torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成数据集\n",
    "和之前一样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用utils.data读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "# combine featues and labels of dataset\n",
    "dataset = Data.TensorDataset(features, labels)\n",
    "data_iter = Data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,  # 使用多线程读取\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2286, -0.6388],\n",
      "        [-0.2149,  0.1746],\n",
      "        [ 0.8046,  1.5490],\n",
      "        [ 1.4931, -1.5149],\n",
      "        [-0.6078,  0.6868],\n",
      "        [-1.7376, -1.3728],\n",
      "        [ 0.3141,  0.9148],\n",
      "        [-1.1578, -0.1637],\n",
      "        [ 1.3591,  0.3041],\n",
      "        [ 1.8199, -0.9232]]) \n",
      " tensor([ 6.8157,  3.1804,  0.5443, 12.3583,  0.6542,  5.3831,  1.7069,  2.4419,\n",
      "         5.8872, 10.9811])\n"
     ]
    }
   ],
   "source": [
    "## 测试\n",
    "for X, y in data_iter:\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearNet(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, n_feature):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.linear = nn.Linear(n_feature, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        return y\n",
    "net = LinearNet(nb_inputs)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "Linear(in_features=2, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "## 扩展为多层序列模型\n",
    "# 方式1\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(nb_inputs, 1)\n",
    ")\n",
    "# 方式2\n",
    "net = nn.Sequential()\n",
    "net.add_module('linear', nn.Linear(nb_inputs, 1))\n",
    "# 方法3\n",
    "from collections import OrderedDict\n",
    "net = nn.Sequential(OrderedDict([\n",
    "          ('linear', nn.Linear(nb_inputs, 1))\n",
    "          # ......\n",
    "        ]))\n",
    "print(net)\n",
    "print(net[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import init\n",
    "\n",
    "init.normal_(net[0].weight, mean=0.0, std=0.01)\n",
    "init.constant_(net[0].bias, val=0.0)  # or you can use `net[0].bias.data.fill_(0)` to modify it directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0031, -0.0052]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 调用损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.03\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.03)   # built-in random gradient descent function\n",
    "print(optimizer)  # function prototype: `torch.optim.SGD(params, lr=, momentum=0, dampening=0, weight_decay=0, nesterov=False)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 0.000102\n",
      "epoch 2, loss: 0.000023\n",
      "epoch 3, loss: 0.000074\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for X, y in data_iter:\n",
    "        output = net(X)\n",
    "        l = loss(output, y.view(-1, 1))\n",
    "        optimizer.zero_grad() # reset gradient, equal to net.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    print('epoch %d, loss: %f' % (epoch, l.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, -3.4] tensor([[ 2.0005, -3.3993]])\n",
      "4.2 tensor([4.1998])\n"
     ]
    }
   ],
   "source": [
    "## 结果对比\n",
    "dense = net[0]\n",
    "print(true_w, dense.weight.data)\n",
    "print(true_b, dense.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 两种方式对比\n",
    "- 从0开始可以理解Linear Regression的模型原理，pytorch可以加快模型构建\n",
    "- 时间上，pytorch的编码并没有提升"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

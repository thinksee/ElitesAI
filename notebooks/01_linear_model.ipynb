{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归\n",
    "    - 线性回归的基本要素\n",
    "    - 线性回归模型从零开始的实现\n",
    "    - 线性回归模型使用pytorch的简洁实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归的基本要素\n",
    "\n",
    "### 模型\n",
    "为了简单起见，这里我们假设价格只取决于房屋状况的两个因素，即面积（平方米）和房龄（年）。接下来我们希望探索价格与这两个因素的具体关系。线性回归假设输出与各个输入之间是线性关系:\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathrm{price} = w_{\\mathrm{area}} \\cdot \\mathrm{area} + w_{\\mathrm{age}} \\cdot \\mathrm{age} + b\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### 数据集\n",
    "我们通常收集一系列的真实数据，例如多栋房屋的真实售出价格和它们对应的面积和房龄。我们希望在这个数据上面寻找模型参数来使模型的预测价格与真实价格的误差最小。在机器学习术语里，该数据集被称为训练数据集（training data set）或训练集（training set），一栋房屋被称为一个样本（sample），其真实售出价格叫作标签（label），用来预测标签的两个因素叫作特征（feature）。特征用来表征样本的特点。\n",
    "### 损失函数\n",
    "在模型训练中，我们需要衡量价格预测值与真实值之间的误差。通常我们会选取一个非负数作为误差，且数值越小表示误差越小。一个常用的选择是平方函数。 它在评估索引为 $i$ 的样本误差的表达式为\n",
    "\n",
    "\n",
    "$$\n",
    "l^{(i)}(\\mathbf{w}, b) = \\frac{1}{2} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2,\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "L(\\mathbf{w}, b) =\\frac{1}{n}\\sum_{i=1}^n l^{(i)}(\\mathbf{w}, b) =\\frac{1}{n} \\sum_{i=1}^n \\frac{1}{2}\\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right)^2.\n",
    "$$\n",
    "\n",
    "\n",
    "### 优化函数 - 随机梯度下降\n",
    "当模型和损失函数形式较为简单时，上面的误差最小化问题的解可以直接用公式表达出来。这类解叫作解析解（analytical solution）。本节使用的线性回归和平方误差刚好属于这个范畴。然而，大多数深度学习模型并没有解析解，只能通过优化算法有限次迭代模型参数来尽可能降低损失函数的值。这类解叫作数值解（numerical solution）。\n",
    "\n",
    "在求数值解的优化算法中，小批量随机梯度下降（mini-batch stochastic gradient descent）在深度学习中被广泛使用。它的算法很简单：先选取一组模型参数的初始值，如随机选取；接下来对参数进行多次迭代，使每次迭代都可能降低损失函数的值。在每次迭代中，先随机均匀采样一个由固定数目训练数据样本所组成的小批量（mini-batch）$\\mathcal{B}$，然后求小批量中数据样本的平均损失有关模型参数的导数（梯度），最后用此结果与预先设定的一个正数的乘积作为模型参数在本次迭代的减小量。   \n",
    "\n",
    "$$\n",
    "(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_{(\\mathbf{w},b)} l^{(i)}(\\mathbf{w},b)\n",
    "$$\n",
    "  \n",
    "学习率: $\\eta$代表在每次优化中，能够学习的步长的大小    \n",
    "批量大小: $\\mathcal{B}$是小批量计算中的批量大小batch size   \n",
    "\n",
    "总结一下，优化函数的有以下两个步骤：\n",
    "\n",
    "- (i)初始化模型参数，一般来说使用随机初始化；\n",
    "- (ii)我们在数据上迭代多次，通过在负梯度方向移动参数来更新每个参数。\n",
    "\n",
    "**注意**\n",
    "梯度上升还是梯度下降和目标优化函数是一直的，若想要优化函数越小，则采用梯度下降，若想要优化函数越大，则采用梯度上升"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "n = 1000\n",
    "a = torch.ones(n)\n",
    "b = torch.ones(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a timer class to record time\n",
    "class Timer(object):\n",
    "    \"\"\"Record multiple running times.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        # start the timer\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        # stop the timer and record time into a list\n",
    "        self.times.append(time.time() - self.start_time)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        # calculate the average and return\n",
    "        return sum(self.times)/len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        # return the sum of recorded time\n",
    "        return sum(self.times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11293 sec'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = Timer()\n",
    "c = torch.zeros(n)\n",
    "for i in range(n):\n",
    "    c[i] = a[i] + b[i]\n",
    "'%.5f sec' % timer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00100 sec'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer.start()\n",
    "d = a + b\n",
    "'%.5f sec' % timer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### 线性回归模型从0开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成数据集\n",
    "使用线性模型随机生成数据集，生成1000个样本数据集，下面是用来生成数据的线性关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_inputs = 2\n",
    "nb_examples = 1000\n",
    "# set true weight and bias in order to generate corresponded label\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "\n",
    "features = torch.randn(nb_examples, nb_inputs,\n",
    "                      dtype=torch.float32)\n",
    "labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\n",
    "labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()),\n",
    "                       dtype=torch.float32)  # 添加噪音"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(features[:, 1].numpy(), labels.numpy(), 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据读写器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))  # \n",
    "    random.shuffle(indices)  # random read 10 samples\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)]) # the last time may be not enough for a whole batch\n",
    "        yield  features.index_select(0, j), labels.index_select(0, j)  # 进行行维度的选择，即每次选择j行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3926,  0.0970],\n",
      "        [ 2.1876, -0.6205],\n",
      "        [ 1.7217,  0.9906],\n",
      "        [ 0.1699, -0.0990],\n",
      "        [-0.0395, -0.4934],\n",
      "        [ 1.2824, -0.2712],\n",
      "        [ 1.5302, -1.7599],\n",
      "        [ 0.9036, -0.3541],\n",
      "        [-0.2322, -0.2395],\n",
      "        [-0.5971, -0.1302]]) \n",
      " tensor([ 4.6684, 10.6793,  4.2849,  4.8643,  5.8006,  7.6827, 13.2421,  7.2142,\n",
      "         4.5403,  3.4487])\n"
     ]
    }
   ],
   "source": [
    "# test data_iter\n",
    "batch_size = 10\n",
    "\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0023],\n",
      "        [0.0011]]) tensor([0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor(np.random.normal(0, 0.01, (nb_inputs, 1)), dtype=torch.float32)\n",
    "b = torch.zeros(1, dtype=torch.float32)\n",
    "print(w,b)\n",
    "w.requires_grad_(requires_grad=True)  # 是否参与梯度下降\n",
    "b.requires_grad_(requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义模型\n",
    "使用简单的线性归回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X, w, b):\n",
    "    return torch.mm(X, w) + b  # 矩阵乘法+广播机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义损失函数\n",
    "**问题2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y):   # 均方误差\n",
    "#     return (y_hat - y.view(y_hat.size())) ** 2 / 2\n",
    "    return (y_hat.view(-1) - y) ** 2 / 2\n",
    "#     return -(y_hat - y.view(-1)) ** 2 / 2  # \n",
    "#     return (y_hat - y.view(y_hat.shape)) ** 2 / 2\n",
    "#     return (y_hat - y.view(-1, 1)) ** 2 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里采用优化函数使用的是小批量随机梯度下降\n",
    "def sgd(params, lr, batch_size): \n",
    "    for param in params:\n",
    "        param.data += lr * param.grad / batch_size # ues .data to operate param without gradient track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.37477 sec'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# super parameters init\n",
    "lr = 0.03 # learning rate\n",
    "num_epochs = 5\n",
    "\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "timer = Timer()\n",
    "# training\n",
    "for epoch in range(num_epochs):  # training repeats num_epochs times\n",
    "    # in each epoch, all the samples in dataset will be used once\n",
    "    \n",
    "    # X is the feature and y is the label of a batch sample\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        l = loss(net(X, w, b), y).sum() \n",
    "        \n",
    "        # calculate the gradient of batch sample loss \n",
    "        l.backward()  \n",
    "        # using small batch random gradient descent to iter model parameters\n",
    "        sgd([w, b], lr, batch_size)  \n",
    "        # reset parameter gradient\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "    train_l = loss(net(features, w, b), labels)\n",
    "'%.5f sec' % timer.stop()  \n",
    "#     print(net(features, w, b).shape, labels.shape) # 所以labels需要扩展\n",
    "#     print('epoch %d, loss %f' % (epoch + 1, train_l.mean().item()))\n",
    "# print(net(features, w, b).shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1121)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squared_loss(torch.Tensor([2.33, 1.07, 1.23]), torch.Tensor([3.14, 0.98, 1.32])).sum()/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### 线性模型pytorch简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "torch.manual_seed(2020)\n",
    "\n",
    "torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成数据集\n",
    "和之前一样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用utils.data读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "# combine featues and labels of dataset\n",
    "dataset = Data.TensorDataset(features, labels)\n",
    "data_iter = Data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,  # 使用多线程读取\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.3061, -1.0165],\n",
      "        [ 1.1349,  0.5120],\n",
      "        [ 1.8823,  0.5276],\n",
      "        [ 1.6269,  1.2606],\n",
      "        [-1.3442,  0.6318],\n",
      "        [-0.1605,  0.7786],\n",
      "        [-0.6842,  0.3046],\n",
      "        [-0.0402, -0.8618],\n",
      "        [ 0.0060,  0.0063],\n",
      "        [-0.9245,  0.3125]]) \n",
      " tensor([12.2726,  4.7196,  6.1756,  3.1801, -0.6359,  1.2296,  1.7908,  7.0437,\n",
      "         4.1803,  1.2931])\n"
     ]
    }
   ],
   "source": [
    "## 测试\n",
    "for X, y in data_iter:\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearNet(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, n_feature):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.linear = nn.Linear(n_feature, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        return y\n",
    "net = LinearNet(nb_inputs)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "Linear(in_features=2, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "## 扩展为多层序列模型\n",
    "# 方式1\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(nb_inputs, 1)\n",
    ")\n",
    "# 方式2\n",
    "net = nn.Sequential()\n",
    "net.add_module('linear', nn.Linear(nb_inputs, 1))\n",
    "# 方法3\n",
    "from collections import OrderedDict\n",
    "net = nn.Sequential(OrderedDict([\n",
    "          ('linear', nn.Linear(nb_inputs, 1))\n",
    "          # ......\n",
    "        ]))\n",
    "print(net)\n",
    "print(net[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import init\n",
    "\n",
    "init.normal_(net[0].weight, mean=0.0, std=0.01)\n",
    "init.constant_(net[0].bias, val=0.0)  # or you can use `net[0].bias.data.fill_(0)` to modify it directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0016,  0.0022]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 调用损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.03\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.03)   # built-in random gradient descent function\n",
    "print(optimizer)  # function prototype: `torch.optim.SGD(params, lr=, momentum=0, dampening=0, weight_decay=0, nesterov=False)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'17.46994 sec'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = Timer()\n",
    "num_epochs = 5\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for X, y in data_iter:\n",
    "        output = net(X)\n",
    "        l = loss(output, y.view(-1, 1))\n",
    "        optimizer.zero_grad() # reset gradient, equal to net.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "'%.5f sec' % timer.stop()\n",
    "#     print('epoch %d, loss: %f' % (epoch, l.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, -3.4] tensor([[ 1.9995, -3.4004]])\n",
      "4.2 tensor([4.2002])\n"
     ]
    }
   ],
   "source": [
    "## 结果对比\n",
    "dense = net[0]\n",
    "print(true_w, dense.weight.data)\n",
    "print(true_b, dense.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 两种方式对比\n",
    "- 从0开始可以理解Linear Regression的模型原理，pytorch可以加快模型构建\n",
    "- 时间上，pytorch的编码并没有提升"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

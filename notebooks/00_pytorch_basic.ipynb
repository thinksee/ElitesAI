{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor概述\n",
    "对于Tensor的操作很多，从接口角度来讲，可以分为两类\n",
    "- torch.function，如torch.sum、torch.add等\n",
    "- tensor.function，如tensor.view、tensor.add等\n",
    "\n",
    "其中，关于Tensor很多操作都是等价的，如torch.add(x, y)和x.add(y)等价。\n",
    "\n",
    "从修改方式的角度来看，可以分为两类：\n",
    "- 不修改自身数据，如x.add(y)，x的数据不变，返回一个新的Tensor。\n",
    "- 修改自身数据，如x.add_(y)（运算符带下划线），运算结果存在x中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2]) tensor([3, 4]) tensor([4, 6])\n",
      "tensor([5, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2])\n",
    "y = torch.tensor([3,4])\n",
    "z = x.add(y)\n",
    "print(x, y, z)\n",
    "x.add_(z)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5., 6.])\n",
      "tensor([[ 3.0829e-44,  0.0000e+00, -5.2688e+26],\n",
      "        [ 5.1708e-43,  0.0000e+00,  0.0000e+00]])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0.0000e+00, 0.0000e+00, 5.4212e-05],\n",
      "        [2.6080e-09, 1.3553e-05, 2.6807e-09]])\n"
     ]
    }
   ],
   "source": [
    "# 依据list数据生成Tensor\n",
    "print(torch.Tensor([1,2,3,4,5,6]))\n",
    "# 指定形状生成Tensor\n",
    "print(torch.Tensor(2,3))\n",
    "# 直接给定Tensor的形状\n",
    "t = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "# 查看Tensor形状\n",
    "print(t.size())\n",
    "# shape与size()等价方式\n",
    "print(t.shape)\n",
    "# 依据已有形状创建Tensor\n",
    "print(torch.Tensor(t.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.Tensor**和**torch.tensor**的区别\n",
    "- torch.Tensor是torch.empty和torch.tensor之间的一种混合，传入数据时，torch.Tensor使用全局默认dtype(FloatTensor)，而torch.tensor是从数据中推断数据类型。\n",
    "- torch.tensor(1)返回一个固定值1，而torch.Tensor(1)返回的是一大小为1的张量，它是随机初始化的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([inf]) torch.FloatTensor tensor(1) torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.Tensor(1)\n",
    "t2 = torch.tensor(1)\n",
    "print(t1, t1.type(), t2, t2.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自动生成Tensor的一些例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.],\n",
      "        [0., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([ 1.,  4.,  7., 10.])\n",
      "tensor([[0.5309, 0.5507, 0.4731],\n",
      "        [0.9114, 0.0011, 0.4336]])\n",
      "tensor([[ 0.0360,  0.5883,  0.0856],\n",
      "        [-0.4142, -1.0687,  1.4036]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 生成一个单位矩阵\n",
    "print(torch.eye(2,2))\n",
    "# 自动生成全是0的矩阵\n",
    "print(torch.zeros(2,3))\n",
    "# \n",
    "print(torch.linspace(1, 10, 4))\n",
    "# 生成满足均匀分布随机数\n",
    "print(torch.rand(2,3))\n",
    "# 生成满足标准分布随机数\n",
    "print(torch.randn(2,3))\n",
    "# 返回所给数据形状相同，值全为0的张量\n",
    "print(torch.zeros_like(torch.rand(2,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修改Tensor形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "2\n",
      "tensor([[-1.5453,  0.5784],\n",
      "        [-0.9881,  0.1217],\n",
      "        [ 0.0695,  0.1033]])\n",
      "tensor([-1.5453,  0.5784, -0.9881,  0.1217,  0.0695,  0.1033])\n",
      "torch.Size([6]) torch.Size([2, 3])\n",
      "tensor([[-1.5453,  0.5784, -0.9881,  0.1217,  0.0695,  0.1033]]) torch.Size([1, 6])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "print(x.size())\n",
    "print(x.dim())\n",
    "# 修改x的形状\n",
    "print(x.view(3,2))\n",
    "y = x.view(-1)\n",
    "print(y)\n",
    "print(y.shape, x.shape)\n",
    "z = torch.unsqueeze(y, 0)  # 对y添加一个维度\n",
    "print(z, z.size())\n",
    "print(z.numel())  #计算z中元素的个数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 索引操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2372, -0.9604,  1.5415],\n",
      "        [-0.4079,  0.8806,  0.0529]])\n",
      "The First Row tensor([ 1.2372, -0.9604,  1.5415])\n",
      "The last col tensor([1.5415, 0.0529])\n",
      "生成是否大于0的Byter张量 tensor([[ True, False,  True],\n",
      "        [False,  True,  True]])\n",
      "tensor([1.2372, 1.5415, 0.8806, 0.0529])\n",
      "tensor([[0, 0],\n",
      "        [0, 2],\n",
      "        [1, 1],\n",
      "        [1, 2]])\n",
      "index tensor([[0, 1, 1]])\n",
      "tensor([[1.2372, 0.8806, 0.0529]])\n",
      "index tensor([[0, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "a tensor([[ 1.2372, -0.9604, -0.9604],\n",
      "        [ 0.8806,  0.8806,  0.8806]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[ 1.2372, -0.9604,  0.0000],\n",
      "        [ 0.0000,  0.8806,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# 设置一个随机种子\n",
    "torch.manual_seed(2020)\n",
    "# 生成一个2x3的矩阵\n",
    "x = torch.randn(2, 3)\n",
    "print(x)\n",
    "print('The First Row', x[0,:])\n",
    "print('The last col', x[:, -1])\n",
    "mask = x > 0\n",
    "print('生成是否大于0的Byter张量', mask)\n",
    "# 获取其值\n",
    "print(torch.masked_select(x, mask))\n",
    "# 获取非0下标，即行列坐标\n",
    "print(torch.nonzero(mask))  # False:0, True:1\n",
    "index = torch.LongTensor([[0, 1, 1]]) \n",
    "print('index', index)\n",
    "# out[i][j][k] = input[index[i][j][k]][j][k]  # dim=0\n",
    "# out[i][j][k] = input[i][index[i][j][k]][k]  # dim=1\n",
    "# out[i][j][k] = input[i][j][index[i][j][k]]  # dim=2\n",
    "\n",
    "print(torch.gather(x, 0, index)) # torch.gather(input, dim, index, out=None) → Tensor\n",
    "index = torch.LongTensor([[0,1,1], [1,1,1]])\n",
    "print('index', index)\n",
    "a = torch.gather(x, 1, index)\n",
    "print('a', a)\n",
    "z = torch.zeros(2,3)\n",
    "print(z)\n",
    "z.scatter_(1, index, a)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**numpy广播机制**\n",
    "- 让所有输入数组都向其中shape最长的数组看齐，不足的部分则通过在前面加1补齐\n",
    "- 输入数组的shape是输入数组shape的各个轴上的最大值\n",
    "- 若输入数组的某个轴和输入数组的对应轴的长度想相同或者某个轴的长度为1时，这个数组能被用来计算，否则出错\n",
    "- 当输入数组的某个轴的长度为1时，沿着此轴运算时都用（或者复制）此轴上的第一组值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1) (3,)\n",
      "[[ 0]\n",
      " [10]\n",
      " [20]\n",
      " [30]] [0 1 2]\n",
      "(4, 3) [[ 0  1  2]\n",
      " [10 11 12]\n",
      " [20 21 22]\n",
      " [30 31 32]]\n"
     ]
    }
   ],
   "source": [
    "# 计算A+B，其中A是4x1矩阵，B是（3，）\n",
    "A = np.arange(0, 40, 10).reshape(4, 1)\n",
    "B = np.arange(0, 3)\n",
    "print(A.shape, B.shape)\n",
    "print(A, B)\n",
    "C = A + B\n",
    "print(C.shape, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解释**\n",
    "\n",
    "由于A的shape长于B的shape，此时B向A看齐，把B变为$(1,3)$, 然后输出值为各轴上的最大值，则输出结果为$(4,3)$。\n",
    "\n",
    "下面的问题就是$(4,3) \\gets (4,1)$以及$(4,3) \\gets (1,3)$，则A变为$[[0, 0, 0], [10, 10, 10], [20, 20, 20], [30, 30, 30]]$, $B=[[0, 1, 2]]$变为$[[0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1,2]]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0]\n",
      " [10]\n",
      " [20]\n",
      " [30]] [0 1 2]\n",
      "tensor([[ 0],\n",
      "        [10],\n",
      "        [20],\n",
      "        [30]], dtype=torch.int32) tensor([0, 1, 2], dtype=torch.int32)\n",
      "tensor([[ 0,  1,  2],\n",
      "        [10, 11, 12],\n",
      "        [20, 21, 22],\n",
      "        [30, 31, 32]], dtype=torch.int32)\n",
      "tensor([[0, 1, 2]], dtype=torch.int32)\n",
      "tensor([[ 0,  1,  2],\n",
      "        [10, 11, 12],\n",
      "        [20, 21, 22],\n",
      "        [30, 31, 32]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(A, B)\n",
    "# ndarray转换为Tensor\n",
    "A1 = torch.from_numpy(A)\n",
    "B1 = torch.from_numpy(B)\n",
    "print(A1, B1)\n",
    "# Tensor自动实现广播\n",
    "C = A1 + B1\n",
    "print(C)\n",
    "# 手动配置\n",
    "B2 = B1.unsqueeze(0) # 0前，1后\n",
    "print(B2)\n",
    "A2 = A1.expand(4,3)\n",
    "B3 = B2.expand(4,3)\n",
    "C1 = B2 + A2\n",
    "print(C1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逐元素操作\n",
    "输入形状和输出形状相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0751,  0.4777, -0.6759]]) tensor([[-2.1489],\n",
      "        [-1.1463],\n",
      "        [-0.2720]]) tensor([[ 1.0066, -0.0416, -1.2853]])\n",
      "tensor([[ 0.1751,  0.5777, -0.5759]])\n",
      "tensor([[0.5188, 0.6172, 0.3372]])\n",
      "tensor([[0.0751, 0.4777, 0.0000]])\n",
      "tensor([[ 0.0751,  0.4777, -0.6759]])\n",
      "tensor([[2.0751, 2.4777, 1.3241]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.randn(1, 3)\n",
    "t1 = torch.randn(3, 1)\n",
    "t2 = torch.randn(1, 3)\n",
    "print(t, t1, t2)\n",
    "# t + 0.1 * (t1/t2)\n",
    "print(torch.addcdiv(t, 0.1, t2, t2))\n",
    "# 计算sigmoid\n",
    "print(torch.sigmoid(t))\n",
    "# 将t限制在[0, 1]之间\n",
    "print(torch.clamp(t, 0, 1))\n",
    "print(t)\n",
    "t.add_(2)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 归并操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  2.,  4.,  6.,  8., 10.])\n",
      "tensor([[ 0.,  2.,  4.],\n",
      "        [ 6.,  8., 10.]])\n",
      "tensor([ 6., 10., 14.])\n",
      "tensor([[ 6., 10., 14.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.linspace(0, 10, 6)\n",
    "print(a)\n",
    "a = a.view((2, 3))\n",
    "print(a)\n",
    "b = a.sum(dim=0) # dim=0 表示沿着y轴进行相加\n",
    "print(b)\n",
    "b= a.sum(dim=0, keepdim=True)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 比较操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  2.,  4.],\n",
      "        [ 6.,  8., 10.]])\n",
      "tensor(10.)\n",
      "torch.return_types.max(\n",
      "values=tensor([ 6.,  8., 10.]),\n",
      "indices=tensor([1, 1, 1]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([[ 6.,  8., 10.],\n",
      "        [ 0.,  2.,  4.]]),\n",
      "indices=tensor([[1, 1, 1],\n",
      "        [0, 0, 0]]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.linspace(0 ,10, 6).view(2,3)\n",
    "print(x)\n",
    "print(torch.max(x))\n",
    "print(torch.max(x, dim=0))\n",
    "print(torch.topk(x, 2, dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18)\n",
      "tensor([[0, 4, 8],\n",
      "        [8, 6, 7]]) tensor([[2, 3, 1, 1],\n",
      "        [1, 1, 5, 1],\n",
      "        [3, 5, 4, 1]])\n",
      "tensor([[28, 44, 52, 12],\n",
      "        [43, 65, 66, 21]]) torch.Size([2, 4])\n",
      "tensor([[[3, 0, 3],\n",
      "         [9, 6, 9],\n",
      "         [0, 7, 1],\n",
      "         [7, 3, 8]],\n",
      "\n",
      "        [[5, 9, 4],\n",
      "         [6, 8, 2],\n",
      "         [1, 7, 9],\n",
      "         [0, 9, 0]]]) tensor([[[3, 4, 0, 3],\n",
      "         [4, 5, 0, 3],\n",
      "         [5, 5, 4, 1]],\n",
      "\n",
      "        [[0, 0, 1, 0],\n",
      "         [3, 0, 3, 0],\n",
      "         [4, 5, 0, 2]]])\n",
      "tensor([[[ 24,  27,  12,  12],\n",
      "         [ 96, 111,  36,  54],\n",
      "         [ 33,  40,   4,  22],\n",
      "         [ 73,  83,  32,  38]],\n",
      "\n",
      "        [[ 43,  20,  32,   8],\n",
      "         [ 32,  10,  30,   4],\n",
      "         [ 57,  45,  22,  18],\n",
      "         [ 27,   0,  27,   0]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([2,3])\n",
    "b = torch.tensor([3,4])\n",
    "print(torch.dot(a, b))\n",
    "x = torch.randint(10, (2,3))\n",
    "y = torch.randint(6, (3,4))\n",
    "print(x, y)\n",
    "t1 = torch.mm(x, y)\n",
    "print(t1, t1.shape)\n",
    "x = torch.randint(10, (2,4,3))\n",
    "y = torch.randint(6, (2,3,4))\n",
    "print(x, y)\n",
    "print(torch.bmm(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
